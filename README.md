# Hidden Markov Models

This is an implementation of *Hidden Markov Models*.  It is split into parts to
demonstrate solutions to the three classical problems solved by HMM's:

1. Finding the probability of an observation vector Y.
2. "Uncovering" the hidden state sequence, given Y.
3. Training the model so that it maximizes the probability P(Y).

The implementation is accompanied by a formal document (in Russian) which is, in
fact, a coursework, written by the author during his study in the St. Petersburg
State University, in 2016.

To run it, you'd need a `jupyter` notebook.  The corresponding html file is also
included for illustrative purposes, but it may be out of sync with the source
file.

If you are interested in technical details or perhaps lonely and want to chat,
drop a mail to `xio@ungrund.org`.  All the best to you.
